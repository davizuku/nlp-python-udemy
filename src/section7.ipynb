{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Neural Networks to Solve NLP Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parts-of-speech tagging (POS)\n",
    "\n",
    "- Assign a category to a word according to its syntactic function.\n",
    "    - noun, pronoun, adjective, determiner, verb, adverb, preposition, conjunction, interjection\n",
    "- Data download link: https://www.clips.uantwerpen.be/conll2000/chunking/\n",
    "- F1 score: \n",
    "\n",
    "$$ F1 = 2 \\frac{precision * recall}{precision + recall} $$\n",
    "$$ precision = \\frac{TruePositives}{TruePositives + FalsePositives} $$\n",
    "$$ recall = \\frac{TruePositives}{TruePositives + FalseNegatives} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(dataset):\n",
    "    dataset = dataset.drop('drop', axis=1)\n",
    "    dataset['word'] = dataset['word'].apply(lambda x: x.lower())\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = preprocess(pd.read_csv('../large_files/chunking/train.txt', sep=' ', names=['word', 'tag', 'drop']))\n",
    "testData = preprocess(pd.read_csv('../large_files/chunking/test.txt', sep=' ', names=['word', 'tag', 'drop']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>confidence</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>in</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pound</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is</td>\n",
       "      <td>VBZ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word  tag\n",
       "0  confidence   NN\n",
       "1          in   IN\n",
       "2         the   DT\n",
       "3       pound   NN\n",
       "4          is  VBZ"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = trainData['word'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = trainData['tag'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NN', 'IN', 'DT', 'VBZ', 'RB', 'VBN', 'TO', 'VB', 'JJ', 'NNS',\n",
       "       'NNP', ',', 'CC', 'POS', '.', 'VBP', 'VBG', 'PRP$', 'CD', '``',\n",
       "       \"''\", 'VBD', 'EX', 'MD', '#', '(', '$', ')', 'NNPS', 'PRP', 'JJS',\n",
       "       'WP', 'RBR', 'JJR', 'WDT', 'WRB', 'RBS', 'PDT', 'RP', ':', 'FW',\n",
       "       'WP$', 'SYM', 'UH'], dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression\n",
    "\n",
    "- Does not capture sequence information: \n",
    "    - p(tag | word) = softmax(W[word_index])\n",
    "- It just maps one single word to one tag. \n",
    "- Ambiguities are not treated by this model\n",
    "    - A word having more than one possible tag\n",
    "    - \"Book a ship to france\"\n",
    "    - \"Ship a book to france\"\n",
    "- Accuracy: > 90%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, Y, vocab_list, tag_list, epochs=10, batch_size=100):\n",
    "        features = [\n",
    "            tf.feature_column.categorical_column_with_vocabulary_list('word', vocabulary_list=vocab_list)\n",
    "        ]\n",
    "        self.model = tf.estimator.LinearClassifier(feature_columns=features, n_classes=len(tag_list), label_vocabulary=tag_list)\n",
    "        input_func = tf.estimator.inputs.pandas_input_fn(x=X,y=Y,batch_size=batch_size,num_epochs=epochs,shuffle=True)\n",
    "        self.model.train(input_func, steps=epochs*len(X)/batch_size)\n",
    "\n",
    "    def evaluate(self, X, Y, batch_size=10):\n",
    "        eval_input_func = tf.estimator.inputs.pandas_input_fn(\n",
    "            x=X,\n",
    "            y=Y,\n",
    "            batch_size=batch_size,\n",
    "            num_epochs=1,\n",
    "            shuffle=False\n",
    "        )\n",
    "        results = self.model.evaluate(eval_input_func)\n",
    "        return results\n",
    "\n",
    "    def predict(self, words):\n",
    "        pred_input_func = tf.estimator.inputs.pandas_input_fn(\n",
    "              x=pd.DataFrame.from_dict({'word': words}),\n",
    "              batch_size=100,\n",
    "              num_epochs=1,\n",
    "              shuffle=False\n",
    "        )\n",
    "        predictions = self.model.predict(pred_input_func)\n",
    "        return list(predictions)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmphd4s7hb3\n",
      "INFO:tensorflow:Using config: {'_global_id_in_cluster': 0, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_eval_distribute': None, '_num_worker_replicas': 1, '_model_dir': '/tmp/tmphd4s7hb3', '_is_chief': True, '_save_summary_steps': 100, '_tf_random_seed': None, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_service': None, '_evaluation_master': '', '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_experimental_distribute': None, '_keep_checkpoint_every_n_hours': 10000, '_train_distribute': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f7a80638f28>, '_protocol': None, '_device_fn': None, '_log_step_count_steps': 100, '_task_id': 0, '_master': '', '_num_ps_replicas': 0}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmphd4s7hb3/model.ckpt.\n",
      "INFO:tensorflow:loss = 378.41898, step = 1\n",
      "INFO:tensorflow:global_step/sec: 250.013\n",
      "INFO:tensorflow:loss = 175.13567, step = 101 (0.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 275.721\n",
      "INFO:tensorflow:loss = 115.27223, step = 201 (0.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 283.5\n",
      "INFO:tensorflow:loss = 99.46385, step = 301 (0.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.615\n",
      "INFO:tensorflow:loss = 111.201294, step = 401 (0.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.235\n",
      "INFO:tensorflow:loss = 104.31864, step = 501 (0.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 282.438\n",
      "INFO:tensorflow:loss = 99.747444, step = 601 (0.357 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.754\n",
      "INFO:tensorflow:loss = 81.38308, step = 701 (0.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.339\n",
      "INFO:tensorflow:loss = 113.89626, step = 801 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.624\n",
      "INFO:tensorflow:loss = 81.329124, step = 901 (0.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 233.913\n",
      "INFO:tensorflow:loss = 87.07567, step = 1001 (0.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 177.638\n",
      "INFO:tensorflow:loss = 93.336945, step = 1101 (0.556 sec)\n",
      "INFO:tensorflow:global_step/sec: 180.992\n",
      "INFO:tensorflow:loss = 89.6155, step = 1201 (0.573 sec)\n",
      "INFO:tensorflow:global_step/sec: 230.125\n",
      "INFO:tensorflow:loss = 92.077484, step = 1301 (0.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 186.697\n",
      "INFO:tensorflow:loss = 82.33485, step = 1401 (0.544 sec)\n",
      "INFO:tensorflow:global_step/sec: 179.039\n",
      "INFO:tensorflow:loss = 48.949768, step = 1501 (0.559 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.496\n",
      "INFO:tensorflow:loss = 70.6137, step = 1601 (0.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.957\n",
      "INFO:tensorflow:loss = 76.18465, step = 1701 (0.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.925\n",
      "INFO:tensorflow:loss = 68.68292, step = 1801 (0.502 sec)\n",
      "INFO:tensorflow:global_step/sec: 241.448\n",
      "INFO:tensorflow:loss = 84.56786, step = 1901 (0.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.357\n",
      "INFO:tensorflow:loss = 60.273045, step = 2001 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.22\n",
      "INFO:tensorflow:loss = 77.70564, step = 2101 (0.514 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.496\n",
      "INFO:tensorflow:loss = 64.4099, step = 2201 (0.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.344\n",
      "INFO:tensorflow:loss = 50.43498, step = 2301 (0.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.279\n",
      "INFO:tensorflow:loss = 57.232063, step = 2401 (0.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.183\n",
      "INFO:tensorflow:loss = 61.233166, step = 2501 (0.395 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.369\n",
      "INFO:tensorflow:loss = 54.77946, step = 2601 (0.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.965\n",
      "INFO:tensorflow:loss = 48.578438, step = 2701 (0.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 237.195\n",
      "INFO:tensorflow:loss = 67.343285, step = 2801 (0.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.046\n",
      "INFO:tensorflow:loss = 61.00597, step = 2901 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 241.521\n",
      "INFO:tensorflow:loss = 64.17991, step = 3001 (0.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.992\n",
      "INFO:tensorflow:loss = 52.280857, step = 3101 (0.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.037\n",
      "INFO:tensorflow:loss = 43.110954, step = 3201 (0.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.558\n",
      "INFO:tensorflow:loss = 55.046246, step = 3301 (0.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.239\n",
      "INFO:tensorflow:loss = 61.483315, step = 3401 (0.410 sec)\n",
      "INFO:tensorflow:global_step/sec: 179.251\n",
      "INFO:tensorflow:loss = 61.310528, step = 3501 (0.568 sec)\n",
      "INFO:tensorflow:global_step/sec: 174.195\n",
      "INFO:tensorflow:loss = 40.758995, step = 3601 (0.562 sec)\n",
      "INFO:tensorflow:global_step/sec: 169.396\n",
      "INFO:tensorflow:loss = 64.12301, step = 3701 (0.603 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.886\n",
      "INFO:tensorflow:loss = 47.63024, step = 3801 (0.642 sec)\n",
      "INFO:tensorflow:global_step/sec: 195.746\n",
      "INFO:tensorflow:loss = 35.893044, step = 3901 (0.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.534\n",
      "INFO:tensorflow:loss = 54.75361, step = 4001 (0.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.616\n",
      "INFO:tensorflow:loss = 57.38589, step = 4101 (0.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 182.875\n",
      "INFO:tensorflow:loss = 55.771248, step = 4201 (0.529 sec)\n",
      "INFO:tensorflow:global_step/sec: 190.502\n",
      "INFO:tensorflow:loss = 54.943092, step = 4301 (0.522 sec)\n",
      "INFO:tensorflow:global_step/sec: 186.814\n",
      "INFO:tensorflow:loss = 51.890427, step = 4401 (0.557 sec)\n",
      "INFO:tensorflow:global_step/sec: 177.639\n",
      "INFO:tensorflow:loss = 50.504295, step = 4501 (0.549 sec)\n",
      "INFO:tensorflow:global_step/sec: 194.489\n",
      "INFO:tensorflow:loss = 44.61165, step = 4601 (0.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.06\n",
      "INFO:tensorflow:loss = 42.36319, step = 4701 (0.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.66\n",
      "INFO:tensorflow:loss = 60.693092, step = 4801 (0.457 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.611\n",
      "INFO:tensorflow:loss = 54.55261, step = 4901 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.545\n",
      "INFO:tensorflow:loss = 57.616577, step = 5001 (0.420 sec)\n",
      "INFO:tensorflow:global_step/sec: 201.723\n",
      "INFO:tensorflow:loss = 33.96763, step = 5101 (0.499 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.256\n",
      "INFO:tensorflow:loss = 35.870537, step = 5201 (0.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.824\n",
      "INFO:tensorflow:loss = 52.513092, step = 5301 (0.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.795\n",
      "INFO:tensorflow:loss = 36.150963, step = 5401 (0.436 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.427\n",
      "INFO:tensorflow:loss = 52.639446, step = 5501 (0.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.938\n",
      "INFO:tensorflow:loss = 47.957737, step = 5601 (0.428 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.226\n",
      "INFO:tensorflow:loss = 46.14966, step = 5701 (0.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.337\n",
      "INFO:tensorflow:loss = 42.29928, step = 5801 (0.429 sec)\n",
      "INFO:tensorflow:global_step/sec: 242.433\n",
      "INFO:tensorflow:loss = 43.545685, step = 5901 (0.410 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.157\n",
      "INFO:tensorflow:loss = 41.948204, step = 6001 (0.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.602\n",
      "INFO:tensorflow:loss = 53.803635, step = 6101 (0.482 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.011\n",
      "INFO:tensorflow:loss = 32.13486, step = 6201 (0.451 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.01\n",
      "INFO:tensorflow:loss = 42.484398, step = 6301 (0.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.453\n",
      "INFO:tensorflow:loss = 46.75588, step = 6401 (0.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.293\n",
      "INFO:tensorflow:loss = 40.158234, step = 6501 (0.425 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.072\n",
      "INFO:tensorflow:loss = 32.116158, step = 6601 (0.485 sec)\n",
      "INFO:tensorflow:global_step/sec: 179.902\n",
      "INFO:tensorflow:loss = 40.18346, step = 6701 (0.563 sec)\n",
      "INFO:tensorflow:global_step/sec: 197.734\n",
      "INFO:tensorflow:loss = 25.949627, step = 6801 (0.509 sec)\n",
      "INFO:tensorflow:global_step/sec: 222.546\n",
      "INFO:tensorflow:loss = 48.37149, step = 6901 (0.439 sec)\n",
      "INFO:tensorflow:global_step/sec: 222.741\n",
      "INFO:tensorflow:loss = 43.43686, step = 7001 (0.450 sec)\n",
      "INFO:tensorflow:global_step/sec: 233.546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 30.987915, step = 7101 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 231.047\n",
      "INFO:tensorflow:loss = 39.588947, step = 7201 (0.423 sec)\n",
      "INFO:tensorflow:global_step/sec: 256.925\n",
      "INFO:tensorflow:loss = 29.076149, step = 7301 (0.388 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.277\n",
      "INFO:tensorflow:loss = 39.514095, step = 7401 (0.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.123\n",
      "INFO:tensorflow:loss = 35.54767, step = 7501 (0.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.236\n",
      "INFO:tensorflow:loss = 35.500275, step = 7601 (0.436 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.017\n",
      "INFO:tensorflow:loss = 57.660866, step = 7701 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.491\n",
      "INFO:tensorflow:loss = 42.751644, step = 7801 (0.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.021\n",
      "INFO:tensorflow:loss = 35.18807, step = 7901 (0.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 231.665\n",
      "INFO:tensorflow:loss = 55.695854, step = 8001 (0.432 sec)\n",
      "INFO:tensorflow:global_step/sec: 222.105\n",
      "INFO:tensorflow:loss = 39.37441, step = 8101 (0.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 171.047\n",
      "INFO:tensorflow:loss = 30.056963, step = 8201 (0.572 sec)\n",
      "INFO:tensorflow:global_step/sec: 186.705\n",
      "INFO:tensorflow:loss = 49.103195, step = 8301 (0.546 sec)\n",
      "INFO:tensorflow:global_step/sec: 191.389\n",
      "INFO:tensorflow:loss = 26.209663, step = 8401 (0.523 sec)\n",
      "INFO:tensorflow:global_step/sec: 231.586\n",
      "INFO:tensorflow:loss = 41.271908, step = 8501 (0.425 sec)\n",
      "INFO:tensorflow:global_step/sec: 233.867\n",
      "INFO:tensorflow:loss = 36.313187, step = 8601 (0.427 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.758\n",
      "INFO:tensorflow:loss = 42.05391, step = 8701 (0.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.788\n",
      "INFO:tensorflow:loss = 39.436657, step = 8801 (0.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.21\n",
      "INFO:tensorflow:loss = 29.50989, step = 8901 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.443\n",
      "INFO:tensorflow:loss = 36.761482, step = 9001 (0.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 155.786\n",
      "INFO:tensorflow:loss = 36.03271, step = 9101 (0.619 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.335\n",
      "INFO:tensorflow:loss = 54.254463, step = 9201 (0.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.986\n",
      "INFO:tensorflow:loss = 21.570314, step = 9301 (0.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.405\n",
      "INFO:tensorflow:loss = 39.91288, step = 9401 (0.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.979\n",
      "INFO:tensorflow:loss = 32.700794, step = 9501 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.061\n",
      "INFO:tensorflow:loss = 40.281803, step = 9601 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.816\n",
      "INFO:tensorflow:loss = 54.89639, step = 9701 (0.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 262.879\n",
      "INFO:tensorflow:loss = 55.875233, step = 9801 (0.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.257\n",
      "INFO:tensorflow:loss = 33.888832, step = 9901 (0.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.395\n",
      "INFO:tensorflow:loss = 29.784924, step = 10001 (0.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.811\n",
      "INFO:tensorflow:loss = 35.032383, step = 10101 (0.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.759\n",
      "INFO:tensorflow:loss = 32.50654, step = 10201 (0.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.662\n",
      "INFO:tensorflow:loss = 34.39039, step = 10301 (0.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.134\n",
      "INFO:tensorflow:loss = 47.093945, step = 10401 (0.420 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.821\n",
      "INFO:tensorflow:loss = 35.79068, step = 10501 (0.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.268\n",
      "INFO:tensorflow:loss = 37.394337, step = 10601 (0.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.139\n",
      "INFO:tensorflow:loss = 43.52201, step = 10701 (0.389 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.28\n",
      "INFO:tensorflow:loss = 34.717022, step = 10801 (0.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.706\n",
      "INFO:tensorflow:loss = 22.969286, step = 10901 (0.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.901\n",
      "INFO:tensorflow:loss = 49.93352, step = 11001 (0.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 254.316\n",
      "INFO:tensorflow:loss = 25.176018, step = 11101 (0.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.7\n",
      "INFO:tensorflow:loss = 32.41032, step = 11201 (0.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.927\n",
      "INFO:tensorflow:loss = 29.820276, step = 11301 (0.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.381\n",
      "INFO:tensorflow:loss = 33.196327, step = 11401 (0.513 sec)\n",
      "INFO:tensorflow:global_step/sec: 262.083\n",
      "INFO:tensorflow:loss = 26.328302, step = 11501 (0.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.215\n",
      "INFO:tensorflow:loss = 24.863323, step = 11601 (0.388 sec)\n",
      "INFO:tensorflow:global_step/sec: 273.446\n",
      "INFO:tensorflow:loss = 20.726225, step = 11701 (0.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.955\n",
      "INFO:tensorflow:loss = 36.95693, step = 11801 (0.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 286.9\n",
      "INFO:tensorflow:loss = 22.441452, step = 11901 (0.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.025\n",
      "INFO:tensorflow:loss = 31.257229, step = 12001 (0.489 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.433\n",
      "INFO:tensorflow:loss = 36.064705, step = 12101 (0.656 sec)\n",
      "INFO:tensorflow:global_step/sec: 230.597\n",
      "INFO:tensorflow:loss = 43.468037, step = 12201 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.895\n",
      "INFO:tensorflow:loss = 38.74566, step = 12301 (0.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.213\n",
      "INFO:tensorflow:loss = 23.57779, step = 12401 (0.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 242.813\n",
      "INFO:tensorflow:loss = 26.535519, step = 12501 (0.411 sec)\n",
      "INFO:tensorflow:global_step/sec: 231.553\n",
      "INFO:tensorflow:loss = 19.052979, step = 12601 (0.434 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.85\n",
      "INFO:tensorflow:loss = 35.673977, step = 12701 (0.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.553\n",
      "INFO:tensorflow:loss = 40.602196, step = 12801 (0.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.531\n",
      "INFO:tensorflow:loss = 30.263968, step = 12901 (0.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.37\n",
      "INFO:tensorflow:loss = 19.828857, step = 13001 (0.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.043\n",
      "INFO:tensorflow:loss = 32.87648, step = 13101 (0.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 200.005\n",
      "INFO:tensorflow:loss = 35.186943, step = 13201 (0.511 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.577\n",
      "INFO:tensorflow:loss = 37.296234, step = 13301 (0.356 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.121\n",
      "INFO:tensorflow:loss = 21.359951, step = 13401 (0.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.519\n",
      "INFO:tensorflow:loss = 37.18804, step = 13501 (0.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 222.863\n",
      "INFO:tensorflow:loss = 28.80053, step = 13601 (0.455 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.372\n",
      "INFO:tensorflow:loss = 33.483772, step = 13701 (0.512 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.73\n",
      "INFO:tensorflow:loss = 27.868843, step = 13801 (0.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.004\n",
      "INFO:tensorflow:loss = 29.696419, step = 13901 (0.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 230.656\n",
      "INFO:tensorflow:loss = 47.19111, step = 14001 (0.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 184.697\n",
      "INFO:tensorflow:loss = 32.75235, step = 14101 (0.541 sec)\n",
      "INFO:tensorflow:global_step/sec: 155.613\n",
      "INFO:tensorflow:loss = 33.05625, step = 14201 (0.639 sec)\n",
      "INFO:tensorflow:global_step/sec: 177.748\n",
      "INFO:tensorflow:loss = 38.569935, step = 14301 (0.567 sec)\n",
      "INFO:tensorflow:global_step/sec: 173.65\n",
      "INFO:tensorflow:loss = 30.32988, step = 14401 (0.573 sec)\n",
      "INFO:tensorflow:global_step/sec: 156.385\n",
      "INFO:tensorflow:loss = 21.30791, step = 14501 (0.640 sec)\n",
      "INFO:tensorflow:global_step/sec: 186.752\n",
      "INFO:tensorflow:loss = 39.61463, step = 14601 (0.537 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.414\n",
      "INFO:tensorflow:loss = 29.803076, step = 14701 (0.498 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.222\n",
      "INFO:tensorflow:loss = 31.116379, step = 14801 (0.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.111\n",
      "INFO:tensorflow:loss = 28.930378, step = 14901 (0.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.471\n",
      "INFO:tensorflow:loss = 23.445017, step = 15001 (0.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.732\n",
      "INFO:tensorflow:loss = 28.400427, step = 15101 (0.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.633\n",
      "INFO:tensorflow:loss = 30.515932, step = 15201 (0.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.231\n",
      "INFO:tensorflow:loss = 34.255165, step = 15301 (0.410 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 226.124\n",
      "INFO:tensorflow:loss = 20.012203, step = 15401 (0.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.853\n",
      "INFO:tensorflow:loss = 35.40974, step = 15501 (0.497 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.678\n",
      "INFO:tensorflow:loss = 41.794556, step = 15601 (0.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.052\n",
      "INFO:tensorflow:loss = 37.339996, step = 15701 (0.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.925\n",
      "INFO:tensorflow:loss = 18.189425, step = 15801 (0.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.724\n",
      "INFO:tensorflow:loss = 33.17208, step = 15901 (0.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 183.913\n",
      "INFO:tensorflow:loss = 35.617386, step = 16001 (0.546 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.552\n",
      "INFO:tensorflow:loss = 33.488907, step = 16101 (0.565 sec)\n",
      "INFO:tensorflow:global_step/sec: 190.908\n",
      "INFO:tensorflow:loss = 32.82385, step = 16201 (0.517 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.49\n",
      "INFO:tensorflow:loss = 21.339346, step = 16301 (0.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 160.06\n",
      "INFO:tensorflow:loss = 17.284256, step = 16401 (0.626 sec)\n",
      "INFO:tensorflow:global_step/sec: 189.399\n",
      "INFO:tensorflow:loss = 29.92346, step = 16501 (0.521 sec)\n",
      "INFO:tensorflow:global_step/sec: 241.12\n",
      "INFO:tensorflow:loss = 20.152496, step = 16601 (0.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.876\n",
      "INFO:tensorflow:loss = 27.133755, step = 16701 (0.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 221.698\n",
      "INFO:tensorflow:loss = 27.363974, step = 16801 (0.451 sec)\n",
      "INFO:tensorflow:global_step/sec: 236.392\n",
      "INFO:tensorflow:loss = 25.82988, step = 16901 (0.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.979\n",
      "INFO:tensorflow:loss = 23.4597, step = 17001 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.834\n",
      "INFO:tensorflow:loss = 33.395622, step = 17101 (0.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.457\n",
      "INFO:tensorflow:loss = 39.604954, step = 17201 (0.394 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.324\n",
      "INFO:tensorflow:loss = 21.274809, step = 17301 (0.489 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.159\n",
      "INFO:tensorflow:loss = 30.895432, step = 17401 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.377\n",
      "INFO:tensorflow:loss = 38.784866, step = 17501 (0.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 229.512\n",
      "INFO:tensorflow:loss = 39.076065, step = 17601 (0.437 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.571\n",
      "INFO:tensorflow:loss = 34.565273, step = 17701 (0.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.577\n",
      "INFO:tensorflow:loss = 28.853271, step = 17801 (0.424 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.304\n",
      "INFO:tensorflow:loss = 22.532152, step = 17901 (0.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.552\n",
      "INFO:tensorflow:loss = 22.054935, step = 18001 (0.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.713\n",
      "INFO:tensorflow:loss = 28.515963, step = 18101 (0.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.721\n",
      "INFO:tensorflow:loss = 29.282238, step = 18201 (0.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 257.102\n",
      "INFO:tensorflow:loss = 36.65966, step = 18301 (0.391 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.269\n",
      "INFO:tensorflow:loss = 19.929937, step = 18401 (0.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 235.549\n",
      "INFO:tensorflow:loss = 34.04266, step = 18501 (0.425 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.168\n",
      "INFO:tensorflow:loss = 22.424131, step = 18601 (0.409 sec)\n",
      "INFO:tensorflow:global_step/sec: 235.353\n",
      "INFO:tensorflow:loss = 38.68982, step = 18701 (0.423 sec)\n",
      "INFO:tensorflow:global_step/sec: 237.351\n",
      "INFO:tensorflow:loss = 28.333643, step = 18801 (0.425 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.904\n",
      "INFO:tensorflow:loss = 22.076021, step = 18901 (0.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 232.893\n",
      "INFO:tensorflow:loss = 23.78278, step = 19001 (0.429 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.386\n",
      "INFO:tensorflow:loss = 25.405436, step = 19101 (0.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.165\n",
      "INFO:tensorflow:loss = 26.460258, step = 19201 (0.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.79\n",
      "INFO:tensorflow:loss = 25.085526, step = 19301 (0.394 sec)\n",
      "INFO:tensorflow:global_step/sec: 257.699\n",
      "INFO:tensorflow:loss = 39.14089, step = 19401 (0.389 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.29\n",
      "INFO:tensorflow:loss = 19.676702, step = 19501 (0.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.145\n",
      "INFO:tensorflow:loss = 30.16071, step = 19601 (0.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.029\n",
      "INFO:tensorflow:loss = 43.603813, step = 19701 (0.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.317\n",
      "INFO:tensorflow:loss = 20.382032, step = 19801 (0.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.08\n",
      "INFO:tensorflow:loss = 21.102104, step = 19901 (0.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 240.723\n",
      "INFO:tensorflow:loss = 23.686668, step = 20001 (0.411 sec)\n",
      "INFO:tensorflow:global_step/sec: 259.688\n",
      "INFO:tensorflow:loss = 28.84106, step = 20101 (0.388 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.551\n",
      "INFO:tensorflow:loss = 37.752754, step = 20201 (0.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.331\n",
      "INFO:tensorflow:loss = 24.959265, step = 20301 (0.478 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.654\n",
      "INFO:tensorflow:loss = 23.720312, step = 20401 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.798\n",
      "INFO:tensorflow:loss = 46.040386, step = 20501 (0.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 242.444\n",
      "INFO:tensorflow:loss = 35.67221, step = 20601 (0.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.277\n",
      "INFO:tensorflow:loss = 39.398537, step = 20701 (0.437 sec)\n",
      "INFO:tensorflow:global_step/sec: 236.73\n",
      "INFO:tensorflow:loss = 29.493748, step = 20801 (0.423 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.809\n",
      "INFO:tensorflow:loss = 24.7968, step = 20901 (0.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 242.731\n",
      "INFO:tensorflow:loss = 31.48389, step = 21001 (0.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 256.527\n",
      "INFO:tensorflow:loss = 28.789637, step = 21101 (0.387 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 21173 into /tmp/tmphd4s7hb3/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 14.650518.\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X=trainData, Y=trainData['tag'], vocab_list=vocabulary.tolist(), tag_list=tags.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-01-02-16:02:18\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmphd4s7hb3/model.ckpt-21173\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-01-02-16:02:31\n",
      "INFO:tensorflow:Saving dict for global step 21173: accuracy = 0.89351374, average_loss = 0.3801966, global_step = 21173, loss = 3.8017251\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 21173: /tmp/tmphd4s7hb3/model.ckpt-21173\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.89351374,\n",
       " 'average_loss': 0.3801966,\n",
       " 'global_step': 21173,\n",
       " 'loss': 3.8017251}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X=testData, Y=testData['tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmphd4s7hb3/model.ckpt-21173\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'book': 'NN',\n",
       " 'car': 'NN',\n",
       " 'house': 'NNP',\n",
       " 'of': 'IN',\n",
       " 'really': 'RB',\n",
       " 'run': 'VB',\n",
       " 'ship': 'NN'}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = ['car', 'book', 'house', 'run', 'ship', 'of', 'really']\n",
    "predictions = model.predict(words)\n",
    "dict(zip(\n",
    "    words, \n",
    "    [ p['classes'][0].decode('utf-8') for p in predictions ]\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recurrent neural networks\n",
    "\n",
    "- Use sequences, use context\n",
    "- Similar to logistic regression model, but with an output entering again to the RNN\n",
    "\n",
    "$$ h(t) = \\sigma(W_x^T x(t) + W_h^T h(t-1) + b) $$\n",
    "\n",
    "- Modern RNNs:\n",
    "    - LSTMs\n",
    "    - GRUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path='../large_files', split_sequences=False):\n",
    "    if not os.path.exists(path + '/chunking'):\n",
    "        print(\"Please create a folder in your local directory called 'chunking'\")\n",
    "        print(\"train.txt and test.txt should be stored in there.\")\n",
    "        print(\"Please check the comments to get the download link.\")\n",
    "        exit()\n",
    "    elif not os.path.exists(path + '/chunking/train.txt'):\n",
    "        print(\"train.txt is not in chunking/train.txt\")\n",
    "        print(\"Please check the comments to get the download link.\")\n",
    "        exit()\n",
    "    elif not os.path.exists(path + '/chunking/test.txt'):\n",
    "        print(\"test.txt is not in chunking/test.txt\")\n",
    "        print(\"Please check the comments to get the download link.\")\n",
    "        exit()\n",
    "\n",
    "    word2idx = {}\n",
    "    tag2idx = {}\n",
    "    word_idx = 1\n",
    "    tag_idx = 1\n",
    "    Xtrain = []\n",
    "    Ytrain = []\n",
    "    currentX = []\n",
    "    currentY = []\n",
    "    for line in open(path + '/chunking/train.txt'):\n",
    "        line = line.rstrip()\n",
    "        if line:\n",
    "            r = line.lower().split()\n",
    "            word, tag, _ = r\n",
    "            if word not in word2idx:\n",
    "                word2idx[word] = word_idx\n",
    "                word_idx += 1\n",
    "            currentX.append(word2idx[word])\n",
    "            \n",
    "            if tag not in tag2idx:\n",
    "                tag2idx[tag] = tag_idx\n",
    "                tag_idx += 1\n",
    "            currentY.append(tag2idx[tag])\n",
    "        elif split_sequences:\n",
    "            Xtrain.append(currentX)\n",
    "            Ytrain.append(currentY)\n",
    "            currentX = []\n",
    "            currentY = []\n",
    "\n",
    "    if not split_sequences:\n",
    "        Xtrain = currentX\n",
    "        Ytrain = currentY\n",
    "\n",
    "    # load and score test data\n",
    "    Xtest = []\n",
    "    Ytest = []\n",
    "    currentX = []\n",
    "    currentY = []\n",
    "    unknownIdx = word_idx\n",
    "    for line in open(path + '/chunking/test.txt'):\n",
    "        line = line.rstrip()\n",
    "        if line:\n",
    "            r = line.lower().split()\n",
    "            word, tag, _ = r\n",
    "            if word in word2idx:\n",
    "                currentX.append(word2idx[word])\n",
    "            else:\n",
    "                currentX.append(unknownIdx) # use this as unknown\n",
    "            currentY.append(tag2idx[tag])\n",
    "        elif split_sequences:\n",
    "            Xtest.append(currentX)\n",
    "            Ytest.append(currentY)\n",
    "            currentX = []\n",
    "            currentY = []\n",
    "    if not split_sequences:\n",
    "        Xtest = currentX\n",
    "        Ytest = currentY\n",
    "\n",
    "    return Xtrain, Ytrain, Xtest, Ytest, word2idx, tag2idx, unknownIdx\n",
    "\n",
    "def flatten(l):\n",
    "    return [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Ytrain, Xtest, Ytest, word2idx, tag2idx, unknownIdx = get_data(split_sequences=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = len(word2idx)\n",
    "K = len(set(flatten(Ytrain)) | set(flatten(Ytest))) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentNeuralNetwork:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, sentences, tags, vocab_size, num_tags, hidden_layer_size=10, embedding_dim=10, batch_size=32, epochs=10, lr=1e-2):\n",
    "        self.sequence_length = max(len(x) for x in sentences)\n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        self.inputs = tf.placeholder(tf.int32, shape=[None, self.sequence_length])\n",
    "        self.targets = tf.placeholder(tf.int32, shape=[None, self.sequence_length])\n",
    "        \n",
    "        We = tf.Variable(np.random.randn(vocab_size, embedding_dim).astype(np.float32))\n",
    "        Wo = tf.Variable(np.random.randn(hidden_layer_size, num_tags).astype(np.float32))\n",
    "        bo = tf.Variable(np.random.randn(num_tags).astype(np.float32))\n",
    "        x = tf.nn.embedding_lookup(We, self.inputs) # batch_size x sequence_length x embedding_dim\n",
    "        x = tf.unstack(x, self.sequence_length, 1)  # sequence_length x batch_size x embedding_dim\n",
    "        \n",
    "        rnn_unit = tf.contrib.rnn.LSTMCell(hidden_layer_size, activation=tf.nn.relu, dtype=tf.float32)\n",
    "        outputs, _ = tf.contrib.rnn.static_rnn(rnn_unit, x, dtype=tf.float32) # sequence_length x batch_size x hidden_layer_size\n",
    "        outputs = tf.transpose(outputs, (1, 0, 2)) # batch_size x sequence_length x hidden_layer_size\n",
    "        outputs = tf.reshape(outputs, (self.sequence_length * batch_size, hidden_layer_size)) # NT x hidden_layer_size\n",
    "        \n",
    "        logits = tf.matmul(outputs, Wo) + bo # NT x K\n",
    "        predictions = tf.argmax(logits, 1)\n",
    "        self.predict_op = tf.reshape(predictions, (batch_size, self.sequence_length))\n",
    "        labels_flat = tf.reshape(self.targets, [-1])\n",
    "        \n",
    "        cost_op = tf.reduce_mean(\n",
    "            tf.nn.softmax_cross_entropy_with_logits(\n",
    "                logits=tf.reduce_max(logits, 1),\n",
    "                labels=labels_flat, \n",
    "            )\n",
    "        )\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "        train_op = optimizer.minimize(cost_op)\n",
    "        init = tf.global_variables_initializer()\n",
    "        \n",
    "        t0 = time.time()\n",
    "        padSents = tf.keras.preprocessing.sequence.pad_sequences(sentences, maxlen=self.sequence_length)\n",
    "        padTags = tf.keras.preprocessing.sequence.pad_sequences(tags, maxlen=self.sequence_length)\n",
    "        self.sess = tf.InteractiveSession()\n",
    "        self.sess.run(init)\n",
    "        costs = []\n",
    "        for epoch in range(epochs):\n",
    "            print(\"Starting epoch {} of {}\".format(epoch, epochs))\n",
    "            # padSents, padTags = shuffle(padSents, padTags)\n",
    "            for b in range(len(padSents) // batch_size):\n",
    "                start = b*batch_size\n",
    "                end = (b+1)*batch_size\n",
    "                _, cost = self.sess.run([train_op, cost_op], feed_dict={\n",
    "                    self.inputs: padSents[start:end],\n",
    "                    self.targets: padTags[start:end]\n",
    "                })\n",
    "                costs.append(cost)\n",
    "        t1 = time.time()\n",
    "        print(\"Training time: \" + str(t1 - t0))\n",
    "        plt.plot(costs)\n",
    "        \n",
    "    def predict(self, sentences):\n",
    "        padSentences = tf.keras.preprocessing.sequence.pad_sequences(sentences, maxlen=self.sequence_length)\n",
    "        return self.sess.run(self.predict_op, feed_dict={inputs: padSentences})     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 0 of 2\n",
      "Starting epoch 1 of 2\n",
      "Training time: 13.70862364768982\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rnnModel = RecurrentNeuralNetwork()\n",
    "rnnModel.fit(Xtrain, Ytrain, V, K, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "indices[1760,71] = 17259 is not in [0, 17258)\n\t [[node embedding_lookup (defined at <ipython-input-229-56ad4feddb58>:15)  = GatherV2[Taxis=DT_INT32, Tindices=DT_INT32, Tparams=DT_FLOAT, _class=[\"loc:@Variable\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Variable/read, _arg_Placeholder_0_0, embedding_lookup/axis)]]\n\nCaused by op 'embedding_lookup', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3191, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-230-1b5cdd9ba8b6>\", line 2, in <module>\n    rnnModel.fit(Xtrain, Ytrain, V, K, epochs=2)\n  File \"<ipython-input-229-56ad4feddb58>\", line 15, in fit\n    x = tf.nn.embedding_lookup(We, self.inputs) # batch_size x sequence_length x embedding_dim\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/embedding_ops.py\", line 313, in embedding_lookup\n    transform_fn=None)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/embedding_ops.py\", line 133, in _embedding_lookup_and_transform\n    result = _clip(array_ops.gather(params[0], ids, name=name),\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/array_ops.py\", line 2675, in gather\n    return gen_array_ops.gather_v2(params, indices, axis, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 3332, in gather_v2\n    \"GatherV2\", params=params, indices=indices, axis=axis, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): indices[1760,71] = 17259 is not in [0, 17258)\n\t [[node embedding_lookup (defined at <ipython-input-229-56ad4feddb58>:15)  = GatherV2[Taxis=DT_INT32, Tindices=DT_INT32, Tparams=DT_FLOAT, _class=[\"loc:@Variable\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Variable/read, _arg_Placeholder_0_0, embedding_lookup/axis)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: indices[1760,71] = 17259 is not in [0, 17258)\n\t [[{{node embedding_lookup}} = GatherV2[Taxis=DT_INT32, Tindices=DT_INT32, Tparams=DT_FLOAT, _class=[\"loc:@Variable\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Variable/read, _arg_Placeholder_0_0, embedding_lookup/axis)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-231-2cb47ef6eb33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mYtest\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYtest\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrnnModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# get test acc. too\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnnModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnnModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mrnnModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mXtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnnModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mYtest\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mn_test_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mn_test_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: indices[1760,71] = 17259 is not in [0, 17258)\n\t [[node embedding_lookup (defined at <ipython-input-229-56ad4feddb58>:15)  = GatherV2[Taxis=DT_INT32, Tindices=DT_INT32, Tparams=DT_FLOAT, _class=[\"loc:@Variable\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Variable/read, _arg_Placeholder_0_0, embedding_lookup/axis)]]\n\nCaused by op 'embedding_lookup', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3191, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-230-1b5cdd9ba8b6>\", line 2, in <module>\n    rnnModel.fit(Xtrain, Ytrain, V, K, epochs=2)\n  File \"<ipython-input-229-56ad4feddb58>\", line 15, in fit\n    x = tf.nn.embedding_lookup(We, self.inputs) # batch_size x sequence_length x embedding_dim\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/embedding_ops.py\", line 313, in embedding_lookup\n    transform_fn=None)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/embedding_ops.py\", line 133, in _embedding_lookup_and_transform\n    result = _clip(array_ops.gather(params[0], ids, name=name),\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/array_ops.py\", line 2675, in gather\n    return gen_array_ops.gather_v2(params, indices, axis, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 3332, in gather_v2\n    \"GatherV2\", params=params, indices=indices, axis=axis, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): indices[1760,71] = 17259 is not in [0, 17258)\n\t [[node embedding_lookup (defined at <ipython-input-229-56ad4feddb58>:15)  = GatherV2[Taxis=DT_INT32, Tindices=DT_INT32, Tparams=DT_FLOAT, _class=[\"loc:@Variable\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Variable/read, _arg_Placeholder_0_0, embedding_lookup/axis)]]\n"
     ]
    }
   ],
   "source": [
    "Xtest  = tf.keras.preprocessing.sequence.pad_sequences(Xtest,  maxlen=rnnModel.sequence_length)\n",
    "Ytest  = tf.keras.preprocessing.sequence.pad_sequences(Ytest,  maxlen=rnnModel.sequence_length)\n",
    "# get test acc. too\n",
    "p = rnnModel.sess.run(rnnModel.predict_op, feed_dict={rnnModel.inputs: Xtest, rnnModel.targets: Ytest})\n",
    "n_test_correct = 0\n",
    "n_test_total = 0\n",
    "for yi, pi in zip(Ytest, p):\n",
    "    yii = yi[yi > 0]\n",
    "    pii = pi[yi > 0]\n",
    "    n_test_correct += np.sum(yii == pii)\n",
    "    n_test_total += len(yii)\n",
    "test_acc = float(n_test_correct) / n_test_total\n",
    "\n",
    "print(\n",
    "    \"train acc:\", \"%.4f\" % (float(n_test_correct)/n_test_total),\n",
    "    \"test acc:\", \"%.4f\" % test_acc\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden Markov Models\n",
    "\n",
    "- Hidden states = POS tags, observed = words\n",
    "- HMM = Pi, A, B\n",
    "    - Pi = frequency of start tags\n",
    "    - A = p(tag(t) | tag(t-1))\n",
    "    - B = p(word(t) | tag(t))\n",
    "- Can be calculated by just counting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
