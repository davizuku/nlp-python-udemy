{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Neural Networks to Solve NLP Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parts-of-speech tagging (POS)\n",
    "\n",
    "- Assign a category to a word according to its syntactic function.\n",
    "    - noun, pronoun, adjective, determiner, verb, adverb, preposition, conjunction, interjection\n",
    "- Data download link: https://www.clips.uantwerpen.be/conll2000/chunking/\n",
    "- F1 score: \n",
    "\n",
    "$$ F1 = 2 \\frac{precision * recall}{precision + recall} $$\n",
    "$$ precision = \\frac{TruePositives}{TruePositives + FalsePositives} $$\n",
    "$$ recall = \\frac{TruePositives}{TruePositives + FalseNegatives} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(dataset):\n",
    "    dataset = dataset.drop('drop', axis=1)\n",
    "    dataset['word'] = dataset['word'].apply(lambda x: x.lower())\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = preprocess(pd.read_csv('../large_files/chunking/train.txt', sep=' ', names=['word', 'tag', 'drop']))\n",
    "testData = preprocess(pd.read_csv('../large_files/chunking/test.txt', sep=' ', names=['word', 'tag', 'drop']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>confidence</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>in</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pound</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is</td>\n",
       "      <td>VBZ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word  tag\n",
       "0  confidence   NN\n",
       "1          in   IN\n",
       "2         the   DT\n",
       "3       pound   NN\n",
       "4          is  VBZ"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = trainData['word'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = trainData['tag'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NN', 'IN', 'DT', 'VBZ', 'RB', 'VBN', 'TO', 'VB', 'JJ', 'NNS',\n",
       "       'NNP', ',', 'CC', 'POS', '.', 'VBP', 'VBG', 'PRP$', 'CD', '``',\n",
       "       \"''\", 'VBD', 'EX', 'MD', '#', '(', '$', ')', 'NNPS', 'PRP', 'JJS',\n",
       "       'WP', 'RBR', 'JJR', 'WDT', 'WRB', 'RBS', 'PDT', 'RP', ':', 'FW',\n",
       "       'WP$', 'SYM', 'UH'], dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression\n",
    "\n",
    "- Does not capture sequence information: \n",
    "    - p(tag | word) = softmax(W[word_index])\n",
    "- It just maps one single word to one tag. \n",
    "- Ambiguities are not treated by this model\n",
    "    - A word having more than one possible tag\n",
    "    - \"Book a ship to france\"\n",
    "    - \"Ship a book to france\"\n",
    "- Accuracy: > 90%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, Y, vocab_list, tag_list, epochs=10, batch_size=100):\n",
    "        features = [\n",
    "            tf.feature_column.categorical_column_with_vocabulary_list('word', vocabulary_list=vocab_list)\n",
    "        ]\n",
    "        self.model = tf.estimator.LinearClassifier(feature_columns=features, n_classes=len(tag_list), label_vocabulary=tag_list)\n",
    "        input_func = tf.estimator.inputs.pandas_input_fn(x=X,y=Y,batch_size=batch_size,num_epochs=epochs,shuffle=True)\n",
    "        self.model.train(input_func, steps=epochs*len(X)/batch_size)\n",
    "\n",
    "    def evaluate(self, X, Y, batch_size=10):\n",
    "        eval_input_func = tf.estimator.inputs.pandas_input_fn(\n",
    "            x=X,\n",
    "            y=Y,\n",
    "            batch_size=batch_size,\n",
    "            num_epochs=1,\n",
    "            shuffle=False\n",
    "        )\n",
    "        results = self.model.evaluate(eval_input_func)\n",
    "        return results\n",
    "\n",
    "    def predict(self, words):\n",
    "        pred_input_func = tf.estimator.inputs.pandas_input_fn(\n",
    "              x=pd.DataFrame.from_dict({'word': words}),\n",
    "              batch_size=100,\n",
    "              num_epochs=1,\n",
    "              shuffle=False\n",
    "        )\n",
    "        predictions = self.model.predict(pred_input_func)\n",
    "        return list(predictions)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmphd4s7hb3\n",
      "INFO:tensorflow:Using config: {'_global_id_in_cluster': 0, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_eval_distribute': None, '_num_worker_replicas': 1, '_model_dir': '/tmp/tmphd4s7hb3', '_is_chief': True, '_save_summary_steps': 100, '_tf_random_seed': None, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_service': None, '_evaluation_master': '', '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_experimental_distribute': None, '_keep_checkpoint_every_n_hours': 10000, '_train_distribute': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f7a80638f28>, '_protocol': None, '_device_fn': None, '_log_step_count_steps': 100, '_task_id': 0, '_master': '', '_num_ps_replicas': 0}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmphd4s7hb3/model.ckpt.\n",
      "INFO:tensorflow:loss = 378.41898, step = 1\n",
      "INFO:tensorflow:global_step/sec: 250.013\n",
      "INFO:tensorflow:loss = 175.13567, step = 101 (0.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 275.721\n",
      "INFO:tensorflow:loss = 115.27223, step = 201 (0.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 283.5\n",
      "INFO:tensorflow:loss = 99.46385, step = 301 (0.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.615\n",
      "INFO:tensorflow:loss = 111.201294, step = 401 (0.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.235\n",
      "INFO:tensorflow:loss = 104.31864, step = 501 (0.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 282.438\n",
      "INFO:tensorflow:loss = 99.747444, step = 601 (0.357 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.754\n",
      "INFO:tensorflow:loss = 81.38308, step = 701 (0.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.339\n",
      "INFO:tensorflow:loss = 113.89626, step = 801 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.624\n",
      "INFO:tensorflow:loss = 81.329124, step = 901 (0.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 233.913\n",
      "INFO:tensorflow:loss = 87.07567, step = 1001 (0.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 177.638\n",
      "INFO:tensorflow:loss = 93.336945, step = 1101 (0.556 sec)\n",
      "INFO:tensorflow:global_step/sec: 180.992\n",
      "INFO:tensorflow:loss = 89.6155, step = 1201 (0.573 sec)\n",
      "INFO:tensorflow:global_step/sec: 230.125\n",
      "INFO:tensorflow:loss = 92.077484, step = 1301 (0.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 186.697\n",
      "INFO:tensorflow:loss = 82.33485, step = 1401 (0.544 sec)\n",
      "INFO:tensorflow:global_step/sec: 179.039\n",
      "INFO:tensorflow:loss = 48.949768, step = 1501 (0.559 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.496\n",
      "INFO:tensorflow:loss = 70.6137, step = 1601 (0.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.957\n",
      "INFO:tensorflow:loss = 76.18465, step = 1701 (0.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.925\n",
      "INFO:tensorflow:loss = 68.68292, step = 1801 (0.502 sec)\n",
      "INFO:tensorflow:global_step/sec: 241.448\n",
      "INFO:tensorflow:loss = 84.56786, step = 1901 (0.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.357\n",
      "INFO:tensorflow:loss = 60.273045, step = 2001 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.22\n",
      "INFO:tensorflow:loss = 77.70564, step = 2101 (0.514 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.496\n",
      "INFO:tensorflow:loss = 64.4099, step = 2201 (0.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.344\n",
      "INFO:tensorflow:loss = 50.43498, step = 2301 (0.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.279\n",
      "INFO:tensorflow:loss = 57.232063, step = 2401 (0.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.183\n",
      "INFO:tensorflow:loss = 61.233166, step = 2501 (0.395 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.369\n",
      "INFO:tensorflow:loss = 54.77946, step = 2601 (0.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.965\n",
      "INFO:tensorflow:loss = 48.578438, step = 2701 (0.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 237.195\n",
      "INFO:tensorflow:loss = 67.343285, step = 2801 (0.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.046\n",
      "INFO:tensorflow:loss = 61.00597, step = 2901 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 241.521\n",
      "INFO:tensorflow:loss = 64.17991, step = 3001 (0.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.992\n",
      "INFO:tensorflow:loss = 52.280857, step = 3101 (0.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.037\n",
      "INFO:tensorflow:loss = 43.110954, step = 3201 (0.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.558\n",
      "INFO:tensorflow:loss = 55.046246, step = 3301 (0.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.239\n",
      "INFO:tensorflow:loss = 61.483315, step = 3401 (0.410 sec)\n",
      "INFO:tensorflow:global_step/sec: 179.251\n",
      "INFO:tensorflow:loss = 61.310528, step = 3501 (0.568 sec)\n",
      "INFO:tensorflow:global_step/sec: 174.195\n",
      "INFO:tensorflow:loss = 40.758995, step = 3601 (0.562 sec)\n",
      "INFO:tensorflow:global_step/sec: 169.396\n",
      "INFO:tensorflow:loss = 64.12301, step = 3701 (0.603 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.886\n",
      "INFO:tensorflow:loss = 47.63024, step = 3801 (0.642 sec)\n",
      "INFO:tensorflow:global_step/sec: 195.746\n",
      "INFO:tensorflow:loss = 35.893044, step = 3901 (0.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.534\n",
      "INFO:tensorflow:loss = 54.75361, step = 4001 (0.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.616\n",
      "INFO:tensorflow:loss = 57.38589, step = 4101 (0.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 182.875\n",
      "INFO:tensorflow:loss = 55.771248, step = 4201 (0.529 sec)\n",
      "INFO:tensorflow:global_step/sec: 190.502\n",
      "INFO:tensorflow:loss = 54.943092, step = 4301 (0.522 sec)\n",
      "INFO:tensorflow:global_step/sec: 186.814\n",
      "INFO:tensorflow:loss = 51.890427, step = 4401 (0.557 sec)\n",
      "INFO:tensorflow:global_step/sec: 177.639\n",
      "INFO:tensorflow:loss = 50.504295, step = 4501 (0.549 sec)\n",
      "INFO:tensorflow:global_step/sec: 194.489\n",
      "INFO:tensorflow:loss = 44.61165, step = 4601 (0.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.06\n",
      "INFO:tensorflow:loss = 42.36319, step = 4701 (0.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.66\n",
      "INFO:tensorflow:loss = 60.693092, step = 4801 (0.457 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.611\n",
      "INFO:tensorflow:loss = 54.55261, step = 4901 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.545\n",
      "INFO:tensorflow:loss = 57.616577, step = 5001 (0.420 sec)\n",
      "INFO:tensorflow:global_step/sec: 201.723\n",
      "INFO:tensorflow:loss = 33.96763, step = 5101 (0.499 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.256\n",
      "INFO:tensorflow:loss = 35.870537, step = 5201 (0.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.824\n",
      "INFO:tensorflow:loss = 52.513092, step = 5301 (0.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.795\n",
      "INFO:tensorflow:loss = 36.150963, step = 5401 (0.436 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.427\n",
      "INFO:tensorflow:loss = 52.639446, step = 5501 (0.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.938\n",
      "INFO:tensorflow:loss = 47.957737, step = 5601 (0.428 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.226\n",
      "INFO:tensorflow:loss = 46.14966, step = 5701 (0.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.337\n",
      "INFO:tensorflow:loss = 42.29928, step = 5801 (0.429 sec)\n",
      "INFO:tensorflow:global_step/sec: 242.433\n",
      "INFO:tensorflow:loss = 43.545685, step = 5901 (0.410 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.157\n",
      "INFO:tensorflow:loss = 41.948204, step = 6001 (0.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.602\n",
      "INFO:tensorflow:loss = 53.803635, step = 6101 (0.482 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.011\n",
      "INFO:tensorflow:loss = 32.13486, step = 6201 (0.451 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.01\n",
      "INFO:tensorflow:loss = 42.484398, step = 6301 (0.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.453\n",
      "INFO:tensorflow:loss = 46.75588, step = 6401 (0.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.293\n",
      "INFO:tensorflow:loss = 40.158234, step = 6501 (0.425 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.072\n",
      "INFO:tensorflow:loss = 32.116158, step = 6601 (0.485 sec)\n",
      "INFO:tensorflow:global_step/sec: 179.902\n",
      "INFO:tensorflow:loss = 40.18346, step = 6701 (0.563 sec)\n",
      "INFO:tensorflow:global_step/sec: 197.734\n",
      "INFO:tensorflow:loss = 25.949627, step = 6801 (0.509 sec)\n",
      "INFO:tensorflow:global_step/sec: 222.546\n",
      "INFO:tensorflow:loss = 48.37149, step = 6901 (0.439 sec)\n",
      "INFO:tensorflow:global_step/sec: 222.741\n",
      "INFO:tensorflow:loss = 43.43686, step = 7001 (0.450 sec)\n",
      "INFO:tensorflow:global_step/sec: 233.546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 30.987915, step = 7101 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 231.047\n",
      "INFO:tensorflow:loss = 39.588947, step = 7201 (0.423 sec)\n",
      "INFO:tensorflow:global_step/sec: 256.925\n",
      "INFO:tensorflow:loss = 29.076149, step = 7301 (0.388 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.277\n",
      "INFO:tensorflow:loss = 39.514095, step = 7401 (0.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.123\n",
      "INFO:tensorflow:loss = 35.54767, step = 7501 (0.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.236\n",
      "INFO:tensorflow:loss = 35.500275, step = 7601 (0.436 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.017\n",
      "INFO:tensorflow:loss = 57.660866, step = 7701 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.491\n",
      "INFO:tensorflow:loss = 42.751644, step = 7801 (0.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.021\n",
      "INFO:tensorflow:loss = 35.18807, step = 7901 (0.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 231.665\n",
      "INFO:tensorflow:loss = 55.695854, step = 8001 (0.432 sec)\n",
      "INFO:tensorflow:global_step/sec: 222.105\n",
      "INFO:tensorflow:loss = 39.37441, step = 8101 (0.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 171.047\n",
      "INFO:tensorflow:loss = 30.056963, step = 8201 (0.572 sec)\n",
      "INFO:tensorflow:global_step/sec: 186.705\n",
      "INFO:tensorflow:loss = 49.103195, step = 8301 (0.546 sec)\n",
      "INFO:tensorflow:global_step/sec: 191.389\n",
      "INFO:tensorflow:loss = 26.209663, step = 8401 (0.523 sec)\n",
      "INFO:tensorflow:global_step/sec: 231.586\n",
      "INFO:tensorflow:loss = 41.271908, step = 8501 (0.425 sec)\n",
      "INFO:tensorflow:global_step/sec: 233.867\n",
      "INFO:tensorflow:loss = 36.313187, step = 8601 (0.427 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.758\n",
      "INFO:tensorflow:loss = 42.05391, step = 8701 (0.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.788\n",
      "INFO:tensorflow:loss = 39.436657, step = 8801 (0.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.21\n",
      "INFO:tensorflow:loss = 29.50989, step = 8901 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.443\n",
      "INFO:tensorflow:loss = 36.761482, step = 9001 (0.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 155.786\n",
      "INFO:tensorflow:loss = 36.03271, step = 9101 (0.619 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.335\n",
      "INFO:tensorflow:loss = 54.254463, step = 9201 (0.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.986\n",
      "INFO:tensorflow:loss = 21.570314, step = 9301 (0.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.405\n",
      "INFO:tensorflow:loss = 39.91288, step = 9401 (0.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.979\n",
      "INFO:tensorflow:loss = 32.700794, step = 9501 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.061\n",
      "INFO:tensorflow:loss = 40.281803, step = 9601 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.816\n",
      "INFO:tensorflow:loss = 54.89639, step = 9701 (0.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 262.879\n",
      "INFO:tensorflow:loss = 55.875233, step = 9801 (0.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.257\n",
      "INFO:tensorflow:loss = 33.888832, step = 9901 (0.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.395\n",
      "INFO:tensorflow:loss = 29.784924, step = 10001 (0.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.811\n",
      "INFO:tensorflow:loss = 35.032383, step = 10101 (0.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.759\n",
      "INFO:tensorflow:loss = 32.50654, step = 10201 (0.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.662\n",
      "INFO:tensorflow:loss = 34.39039, step = 10301 (0.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.134\n",
      "INFO:tensorflow:loss = 47.093945, step = 10401 (0.420 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.821\n",
      "INFO:tensorflow:loss = 35.79068, step = 10501 (0.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.268\n",
      "INFO:tensorflow:loss = 37.394337, step = 10601 (0.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.139\n",
      "INFO:tensorflow:loss = 43.52201, step = 10701 (0.389 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.28\n",
      "INFO:tensorflow:loss = 34.717022, step = 10801 (0.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.706\n",
      "INFO:tensorflow:loss = 22.969286, step = 10901 (0.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.901\n",
      "INFO:tensorflow:loss = 49.93352, step = 11001 (0.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 254.316\n",
      "INFO:tensorflow:loss = 25.176018, step = 11101 (0.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.7\n",
      "INFO:tensorflow:loss = 32.41032, step = 11201 (0.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.927\n",
      "INFO:tensorflow:loss = 29.820276, step = 11301 (0.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.381\n",
      "INFO:tensorflow:loss = 33.196327, step = 11401 (0.513 sec)\n",
      "INFO:tensorflow:global_step/sec: 262.083\n",
      "INFO:tensorflow:loss = 26.328302, step = 11501 (0.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.215\n",
      "INFO:tensorflow:loss = 24.863323, step = 11601 (0.388 sec)\n",
      "INFO:tensorflow:global_step/sec: 273.446\n",
      "INFO:tensorflow:loss = 20.726225, step = 11701 (0.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.955\n",
      "INFO:tensorflow:loss = 36.95693, step = 11801 (0.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 286.9\n",
      "INFO:tensorflow:loss = 22.441452, step = 11901 (0.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.025\n",
      "INFO:tensorflow:loss = 31.257229, step = 12001 (0.489 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.433\n",
      "INFO:tensorflow:loss = 36.064705, step = 12101 (0.656 sec)\n",
      "INFO:tensorflow:global_step/sec: 230.597\n",
      "INFO:tensorflow:loss = 43.468037, step = 12201 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.895\n",
      "INFO:tensorflow:loss = 38.74566, step = 12301 (0.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.213\n",
      "INFO:tensorflow:loss = 23.57779, step = 12401 (0.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 242.813\n",
      "INFO:tensorflow:loss = 26.535519, step = 12501 (0.411 sec)\n",
      "INFO:tensorflow:global_step/sec: 231.553\n",
      "INFO:tensorflow:loss = 19.052979, step = 12601 (0.434 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.85\n",
      "INFO:tensorflow:loss = 35.673977, step = 12701 (0.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.553\n",
      "INFO:tensorflow:loss = 40.602196, step = 12801 (0.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.531\n",
      "INFO:tensorflow:loss = 30.263968, step = 12901 (0.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.37\n",
      "INFO:tensorflow:loss = 19.828857, step = 13001 (0.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.043\n",
      "INFO:tensorflow:loss = 32.87648, step = 13101 (0.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 200.005\n",
      "INFO:tensorflow:loss = 35.186943, step = 13201 (0.511 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.577\n",
      "INFO:tensorflow:loss = 37.296234, step = 13301 (0.356 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.121\n",
      "INFO:tensorflow:loss = 21.359951, step = 13401 (0.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.519\n",
      "INFO:tensorflow:loss = 37.18804, step = 13501 (0.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 222.863\n",
      "INFO:tensorflow:loss = 28.80053, step = 13601 (0.455 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.372\n",
      "INFO:tensorflow:loss = 33.483772, step = 13701 (0.512 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.73\n",
      "INFO:tensorflow:loss = 27.868843, step = 13801 (0.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.004\n",
      "INFO:tensorflow:loss = 29.696419, step = 13901 (0.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 230.656\n",
      "INFO:tensorflow:loss = 47.19111, step = 14001 (0.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 184.697\n",
      "INFO:tensorflow:loss = 32.75235, step = 14101 (0.541 sec)\n",
      "INFO:tensorflow:global_step/sec: 155.613\n",
      "INFO:tensorflow:loss = 33.05625, step = 14201 (0.639 sec)\n",
      "INFO:tensorflow:global_step/sec: 177.748\n",
      "INFO:tensorflow:loss = 38.569935, step = 14301 (0.567 sec)\n",
      "INFO:tensorflow:global_step/sec: 173.65\n",
      "INFO:tensorflow:loss = 30.32988, step = 14401 (0.573 sec)\n",
      "INFO:tensorflow:global_step/sec: 156.385\n",
      "INFO:tensorflow:loss = 21.30791, step = 14501 (0.640 sec)\n",
      "INFO:tensorflow:global_step/sec: 186.752\n",
      "INFO:tensorflow:loss = 39.61463, step = 14601 (0.537 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.414\n",
      "INFO:tensorflow:loss = 29.803076, step = 14701 (0.498 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.222\n",
      "INFO:tensorflow:loss = 31.116379, step = 14801 (0.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.111\n",
      "INFO:tensorflow:loss = 28.930378, step = 14901 (0.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.471\n",
      "INFO:tensorflow:loss = 23.445017, step = 15001 (0.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.732\n",
      "INFO:tensorflow:loss = 28.400427, step = 15101 (0.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.633\n",
      "INFO:tensorflow:loss = 30.515932, step = 15201 (0.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.231\n",
      "INFO:tensorflow:loss = 34.255165, step = 15301 (0.410 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 226.124\n",
      "INFO:tensorflow:loss = 20.012203, step = 15401 (0.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.853\n",
      "INFO:tensorflow:loss = 35.40974, step = 15501 (0.497 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.678\n",
      "INFO:tensorflow:loss = 41.794556, step = 15601 (0.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.052\n",
      "INFO:tensorflow:loss = 37.339996, step = 15701 (0.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.925\n",
      "INFO:tensorflow:loss = 18.189425, step = 15801 (0.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.724\n",
      "INFO:tensorflow:loss = 33.17208, step = 15901 (0.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 183.913\n",
      "INFO:tensorflow:loss = 35.617386, step = 16001 (0.546 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.552\n",
      "INFO:tensorflow:loss = 33.488907, step = 16101 (0.565 sec)\n",
      "INFO:tensorflow:global_step/sec: 190.908\n",
      "INFO:tensorflow:loss = 32.82385, step = 16201 (0.517 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.49\n",
      "INFO:tensorflow:loss = 21.339346, step = 16301 (0.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 160.06\n",
      "INFO:tensorflow:loss = 17.284256, step = 16401 (0.626 sec)\n",
      "INFO:tensorflow:global_step/sec: 189.399\n",
      "INFO:tensorflow:loss = 29.92346, step = 16501 (0.521 sec)\n",
      "INFO:tensorflow:global_step/sec: 241.12\n",
      "INFO:tensorflow:loss = 20.152496, step = 16601 (0.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.876\n",
      "INFO:tensorflow:loss = 27.133755, step = 16701 (0.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 221.698\n",
      "INFO:tensorflow:loss = 27.363974, step = 16801 (0.451 sec)\n",
      "INFO:tensorflow:global_step/sec: 236.392\n",
      "INFO:tensorflow:loss = 25.82988, step = 16901 (0.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.979\n",
      "INFO:tensorflow:loss = 23.4597, step = 17001 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.834\n",
      "INFO:tensorflow:loss = 33.395622, step = 17101 (0.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.457\n",
      "INFO:tensorflow:loss = 39.604954, step = 17201 (0.394 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.324\n",
      "INFO:tensorflow:loss = 21.274809, step = 17301 (0.489 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.159\n",
      "INFO:tensorflow:loss = 30.895432, step = 17401 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.377\n",
      "INFO:tensorflow:loss = 38.784866, step = 17501 (0.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 229.512\n",
      "INFO:tensorflow:loss = 39.076065, step = 17601 (0.437 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.571\n",
      "INFO:tensorflow:loss = 34.565273, step = 17701 (0.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.577\n",
      "INFO:tensorflow:loss = 28.853271, step = 17801 (0.424 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.304\n",
      "INFO:tensorflow:loss = 22.532152, step = 17901 (0.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.552\n",
      "INFO:tensorflow:loss = 22.054935, step = 18001 (0.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.713\n",
      "INFO:tensorflow:loss = 28.515963, step = 18101 (0.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.721\n",
      "INFO:tensorflow:loss = 29.282238, step = 18201 (0.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 257.102\n",
      "INFO:tensorflow:loss = 36.65966, step = 18301 (0.391 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.269\n",
      "INFO:tensorflow:loss = 19.929937, step = 18401 (0.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 235.549\n",
      "INFO:tensorflow:loss = 34.04266, step = 18501 (0.425 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.168\n",
      "INFO:tensorflow:loss = 22.424131, step = 18601 (0.409 sec)\n",
      "INFO:tensorflow:global_step/sec: 235.353\n",
      "INFO:tensorflow:loss = 38.68982, step = 18701 (0.423 sec)\n",
      "INFO:tensorflow:global_step/sec: 237.351\n",
      "INFO:tensorflow:loss = 28.333643, step = 18801 (0.425 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.904\n",
      "INFO:tensorflow:loss = 22.076021, step = 18901 (0.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 232.893\n",
      "INFO:tensorflow:loss = 23.78278, step = 19001 (0.429 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.386\n",
      "INFO:tensorflow:loss = 25.405436, step = 19101 (0.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.165\n",
      "INFO:tensorflow:loss = 26.460258, step = 19201 (0.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.79\n",
      "INFO:tensorflow:loss = 25.085526, step = 19301 (0.394 sec)\n",
      "INFO:tensorflow:global_step/sec: 257.699\n",
      "INFO:tensorflow:loss = 39.14089, step = 19401 (0.389 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.29\n",
      "INFO:tensorflow:loss = 19.676702, step = 19501 (0.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.145\n",
      "INFO:tensorflow:loss = 30.16071, step = 19601 (0.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.029\n",
      "INFO:tensorflow:loss = 43.603813, step = 19701 (0.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.317\n",
      "INFO:tensorflow:loss = 20.382032, step = 19801 (0.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.08\n",
      "INFO:tensorflow:loss = 21.102104, step = 19901 (0.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 240.723\n",
      "INFO:tensorflow:loss = 23.686668, step = 20001 (0.411 sec)\n",
      "INFO:tensorflow:global_step/sec: 259.688\n",
      "INFO:tensorflow:loss = 28.84106, step = 20101 (0.388 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.551\n",
      "INFO:tensorflow:loss = 37.752754, step = 20201 (0.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.331\n",
      "INFO:tensorflow:loss = 24.959265, step = 20301 (0.478 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.654\n",
      "INFO:tensorflow:loss = 23.720312, step = 20401 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.798\n",
      "INFO:tensorflow:loss = 46.040386, step = 20501 (0.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 242.444\n",
      "INFO:tensorflow:loss = 35.67221, step = 20601 (0.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.277\n",
      "INFO:tensorflow:loss = 39.398537, step = 20701 (0.437 sec)\n",
      "INFO:tensorflow:global_step/sec: 236.73\n",
      "INFO:tensorflow:loss = 29.493748, step = 20801 (0.423 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.809\n",
      "INFO:tensorflow:loss = 24.7968, step = 20901 (0.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 242.731\n",
      "INFO:tensorflow:loss = 31.48389, step = 21001 (0.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 256.527\n",
      "INFO:tensorflow:loss = 28.789637, step = 21101 (0.387 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 21173 into /tmp/tmphd4s7hb3/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 14.650518.\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X=trainData, Y=trainData['tag'], vocab_list=vocabulary.tolist(), tag_list=tags.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-01-02-16:02:18\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmphd4s7hb3/model.ckpt-21173\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-01-02-16:02:31\n",
      "INFO:tensorflow:Saving dict for global step 21173: accuracy = 0.89351374, average_loss = 0.3801966, global_step = 21173, loss = 3.8017251\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 21173: /tmp/tmphd4s7hb3/model.ckpt-21173\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.89351374,\n",
       " 'average_loss': 0.3801966,\n",
       " 'global_step': 21173,\n",
       " 'loss': 3.8017251}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X=testData, Y=testData['tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmphd4s7hb3/model.ckpt-21173\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'book': 'NN',\n",
       " 'car': 'NN',\n",
       " 'house': 'NNP',\n",
       " 'of': 'IN',\n",
       " 'really': 'RB',\n",
       " 'run': 'VB',\n",
       " 'ship': 'NN'}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = ['car', 'book', 'house', 'run', 'ship', 'of', 'really']\n",
    "predictions = model.predict(words)\n",
    "dict(zip(\n",
    "    words, \n",
    "    [ p['classes'][0].decode('utf-8') for p in predictions ]\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recurrent neural networks\n",
    "\n",
    "- Use sequences, use context\n",
    "- Similar to logistic regression model, but with an output entering again to the RNN\n",
    "\n",
    "$$ h(t) = \\sigma(W_x^T x(t) + W_h^T h(t-1) + b) $$\n",
    "\n",
    "- Modern RNNs:\n",
    "    - LSTMs\n",
    "    - GRUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path='../large_files', split_sequences=False):\n",
    "    if not os.path.exists(path + '/chunking'):\n",
    "        print(\"Please create a folder in your local directory called 'chunking'\")\n",
    "        print(\"train.txt and test.txt should be stored in there.\")\n",
    "        print(\"Please check the comments to get the download link.\")\n",
    "        exit()\n",
    "    elif not os.path.exists(path + '/chunking/train.txt'):\n",
    "        print(\"train.txt is not in chunking/train.txt\")\n",
    "        print(\"Please check the comments to get the download link.\")\n",
    "        exit()\n",
    "    elif not os.path.exists(path + '/chunking/test.txt'):\n",
    "        print(\"test.txt is not in chunking/test.txt\")\n",
    "        print(\"Please check the comments to get the download link.\")\n",
    "        exit()\n",
    "\n",
    "    word2idx = {}\n",
    "    tag2idx = {}\n",
    "    word_idx = 1\n",
    "    tag_idx = 1\n",
    "    Xtrain = []\n",
    "    Ytrain = []\n",
    "    currentX = []\n",
    "    currentY = []\n",
    "    for line in open(path + '/chunking/train.txt'):\n",
    "        line = line.rstrip()\n",
    "        if line:\n",
    "            r = line.lower().split()\n",
    "            word, tag, _ = r\n",
    "            if word not in word2idx:\n",
    "                word2idx[word] = word_idx\n",
    "                word_idx += 1\n",
    "            currentX.append(word2idx[word])\n",
    "            \n",
    "            if tag not in tag2idx:\n",
    "                tag2idx[tag] = tag_idx\n",
    "                tag_idx += 1\n",
    "            currentY.append(tag2idx[tag])\n",
    "        elif split_sequences:\n",
    "            Xtrain.append(currentX)\n",
    "            Ytrain.append(currentY)\n",
    "            currentX = []\n",
    "            currentY = []\n",
    "\n",
    "    if not split_sequences:\n",
    "        Xtrain = currentX\n",
    "        Ytrain = currentY\n",
    "\n",
    "    # load and score test data\n",
    "    Xtest = []\n",
    "    Ytest = []\n",
    "    currentX = []\n",
    "    currentY = []\n",
    "    unknownIdx = word_idx\n",
    "    for line in open(path + '/chunking/test.txt'):\n",
    "        line = line.rstrip()\n",
    "        if line:\n",
    "            r = line.lower().split()\n",
    "            word, tag, _ = r\n",
    "            if word in word2idx:\n",
    "                currentX.append(word2idx[word])\n",
    "            else:\n",
    "                currentX.append(unknownIdx) # use this as unknown\n",
    "            currentY.append(tag2idx[tag])\n",
    "        elif split_sequences:\n",
    "            Xtest.append(currentX)\n",
    "            Ytest.append(currentY)\n",
    "            currentX = []\n",
    "            currentY = []\n",
    "    if not split_sequences:\n",
    "        Xtest = currentX\n",
    "        Ytest = currentY\n",
    "\n",
    "    return Xtrain, Ytrain, Xtest, Ytest, word2idx, tag2idx, unknownIdx\n",
    "\n",
    "def flatten(l):\n",
    "    return [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Ytrain, Xtest, Ytest, word2idx, tag2idx, unknownIdx = get_data(split_sequences=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = len(word2idx) + 2\n",
    "K = len(set(flatten(Ytrain)) | set(flatten(Ytest))) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentNeuralNetwork:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, sentences, tags, vocab_size, num_tags, hidden_layer_size=10, embedding_dim=10, batch_size=32, epochs=10, lr=1e-2):\n",
    "        self.sequence_length = max(len(x) for x in sentences)\n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        self.inputs = tf.placeholder(tf.int32, shape=[None, self.sequence_length])\n",
    "        self.targets = tf.placeholder(tf.int32, shape=[None, self.sequence_length])\n",
    "        \n",
    "        We = tf.Variable(np.random.randn(vocab_size, embedding_dim).astype(np.float32))\n",
    "        Wo = tf.Variable(np.random.randn(hidden_layer_size, num_tags).astype(np.float32))\n",
    "        bo = tf.Variable(np.random.randn(num_tags).astype(np.float32))\n",
    "        x = tf.nn.embedding_lookup(We, self.inputs) # batch_size x sequence_length x embedding_dim\n",
    "        x = tf.unstack(x, self.sequence_length, 1)  # sequence_length x batch_size x embedding_dim\n",
    "        \n",
    "        rnn_unit = tf.contrib.rnn.LSTMCell(hidden_layer_size, activation=tf.nn.relu, dtype=tf.float32)\n",
    "        outputs, _ = tf.contrib.rnn.static_rnn(rnn_unit, x, dtype=tf.float32) # sequence_length x batch_size x hidden_layer_size\n",
    "        outputs = tf.transpose(outputs, (1, 0, 2)) # batch_size x sequence_length x hidden_layer_size\n",
    "        outputs = tf.reshape(outputs, (self.sequence_length * batch_size, hidden_layer_size)) # NT x hidden_layer_size\n",
    "        \n",
    "        logits = tf.matmul(outputs, Wo) + bo # NT x K\n",
    "        predictions = tf.argmax(logits, 1)\n",
    "        self.predict_op = tf.reshape(predictions, (batch_size, self.sequence_length))\n",
    "        labels_flat = tf.reshape(self.targets, [-1])\n",
    "        \n",
    "        cost_op = tf.reduce_mean(\n",
    "            tf.nn.softmax_cross_entropy_with_logits(\n",
    "                logits=tf.reduce_max(logits, 1),\n",
    "                labels=labels_flat, \n",
    "            )\n",
    "        )\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "        train_op = optimizer.minimize(cost_op)\n",
    "        init = tf.global_variables_initializer()\n",
    "        \n",
    "        t0 = time.time()\n",
    "        padSents = tf.keras.preprocessing.sequence.pad_sequences(sentences, maxlen=self.sequence_length)\n",
    "        padTags = tf.keras.preprocessing.sequence.pad_sequences(tags, maxlen=self.sequence_length)\n",
    "        self.sess = tf.InteractiveSession()\n",
    "        self.sess.run(init)\n",
    "        costs = []\n",
    "        for epoch in range(epochs):\n",
    "            print(\"Starting epoch {} of {}\".format(epoch, epochs))\n",
    "            # padSents, padTags = shuffle(padSents, padTags)\n",
    "            for b in range(len(padSents) // batch_size):\n",
    "                start = b*batch_size\n",
    "                end = (b+1)*batch_size\n",
    "                _, cost = self.sess.run([train_op, cost_op], feed_dict={\n",
    "                    self.inputs: padSents[start:end],\n",
    "                    self.targets: padTags[start:end]\n",
    "                })\n",
    "                costs.append(cost)\n",
    "        t1 = time.time()\n",
    "        print(\"Training time: \" + str(t1 - t0))\n",
    "        plt.plot(costs)\n",
    "        \n",
    "    def predict(self, sentences):\n",
    "        padSentences = tf.keras.preprocessing.sequence.pad_sequences(sentences, maxlen=self.sequence_length)\n",
    "        return self.sess.run(self.predict_op, feed_dict={inputs: padSentences})     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-20-56ad4feddb58>:31: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "Starting epoch 0 of 2\n",
      "Starting epoch 1 of 2\n",
      "Training time: 13.128221988677979\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rnnModel = RecurrentNeuralNetwork()\n",
    "rnnModel.fit(Xtrain, Ytrain, V, K, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Input to reshape is a tensor with 1569360 values, but the requested shape has 24960\n\t [[node Reshape (defined at <ipython-input-20-56ad4feddb58>:21)  = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](transpose, Reshape/shape)]]\n\nCaused by op 'Reshape', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3191, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-21-1b5cdd9ba8b6>\", line 2, in <module>\n    rnnModel.fit(Xtrain, Ytrain, V, K, epochs=2)\n  File \"<ipython-input-20-56ad4feddb58>\", line 21, in fit\n    outputs = tf.reshape(outputs, (self.sequence_length * batch_size, hidden_layer_size)) # NT x hidden_layer_size\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 6482, in reshape\n    \"Reshape\", tensor=tensor, shape=shape, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Input to reshape is a tensor with 1569360 values, but the requested shape has 24960\n\t [[node Reshape (defined at <ipython-input-20-56ad4feddb58>:21)  = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](transpose, Reshape/shape)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Input to reshape is a tensor with 1569360 values, but the requested shape has 24960\n\t [[{{node Reshape}} = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](transpose, Reshape/shape)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/notebooks/vendor/machine_learning_examples/nlp_class2/pos_hmm.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mYtest\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYtest\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrnnModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# get test acc. too\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnnModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnnModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mrnnModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mXtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnnModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mYtest\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mn_test_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mn_test_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Input to reshape is a tensor with 1569360 values, but the requested shape has 24960\n\t [[node Reshape (defined at <ipython-input-20-56ad4feddb58>:21)  = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](transpose, Reshape/shape)]]\n\nCaused by op 'Reshape', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3191, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-21-1b5cdd9ba8b6>\", line 2, in <module>\n    rnnModel.fit(Xtrain, Ytrain, V, K, epochs=2)\n  File \"<ipython-input-20-56ad4feddb58>\", line 21, in fit\n    outputs = tf.reshape(outputs, (self.sequence_length * batch_size, hidden_layer_size)) # NT x hidden_layer_size\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 6482, in reshape\n    \"Reshape\", tensor=tensor, shape=shape, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Input to reshape is a tensor with 1569360 values, but the requested shape has 24960\n\t [[node Reshape (defined at <ipython-input-20-56ad4feddb58>:21)  = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](transpose, Reshape/shape)]]\n"
     ]
    }
   ],
   "source": [
    "Xtest  = tf.keras.preprocessing.sequence.pad_sequences(Xtest,  maxlen=rnnModel.sequence_length)\n",
    "Ytest  = tf.keras.preprocessing.sequence.pad_sequences(Ytest,  maxlen=rnnModel.sequence_length)\n",
    "# get test acc. too\n",
    "p = rnnModel.sess.run(rnnModel.predict_op, feed_dict={rnnModel.inputs: Xtest, rnnModel.targets: Ytest})\n",
    "n_test_correct = 0\n",
    "n_test_total = 0\n",
    "for yi, pi in zip(Ytest, p):\n",
    "    yii = yi[yi > 0]\n",
    "    pii = pi[yi > 0]\n",
    "    n_test_correct += np.sum(yii == pii)\n",
    "    n_test_total += len(yii)\n",
    "test_acc = float(n_test_correct) / n_test_total\n",
    "\n",
    "print(\n",
    "    \"train acc:\", \"%.4f\" % (float(n_test_correct)/n_test_total),\n",
    "    \"test acc:\", \"%.4f\" % test_acc\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden Markov Models\n",
    "\n",
    "- Hidden Markov Model is an unsupervised model that aims to maximize the probability of whatever given data. \n",
    "  - Observation: $x = \\{x_1, ..., x_t, ..., x_T\\}$\n",
    "  - Maximize: $p(x)$ \n",
    "\n",
    "- There are some latent variables that cause the observations, but they are hidden. Hidden States.\n",
    "    - Hidden States are not required to be known or represent something\n",
    "    - If hidden states are known, it's all a problem of counting p(A | B) = # (A && B) /  # (B)\n",
    "    - If not, use expectation-maximization technique. \n",
    "\n",
    "- Viterbi algorithm\n",
    "    - Reverses the direction of the problem\n",
    "    - Causality: hidden state *causes* the observation\n",
    "    - Viterbi: given a sequence of observation, what is the most likely sequence of hidden states?\n",
    "    - Input: $\\{x_1, ..., x_T\\}$\n",
    "    - Output: $\\{z_1, ..., z_T\\}$\n",
    "\n",
    "- Part-of-speech tagging\n",
    "    - Observations = words\n",
    "    - Hidden states = tags\n",
    "\n",
    "- Probability for Hidden States: P(tag(t) | tag(t-1)) is given by the grammar rules of the language\n",
    "- Probability for Observations: P(word(t) | tag(t). \n",
    "- Viterbi algorithm uses these two probabilities to run the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath('../vendor/machine_learning_examples/'))\n",
    "from hmm_class.hmmd_scaled import HMM\n",
    "\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(T, Y):\n",
    "    n_correct = 0;\n",
    "    n_total = 0;\n",
    "    for t, y in zip(T, Y):\n",
    "        n_correct += np.sum(t == y)\n",
    "        n_total += len(y)\n",
    "    return float(n_correct) / n_total\n",
    "\n",
    "def total_f1_score(T, Y):\n",
    "    T = np.concatenate(T)\n",
    "    Y = np.concatenate(Y)\n",
    "    return f1_score(T, Y, average=None).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Ytrain, Xtest, Ytest, word2idx, tag2idx, unknownIdx = get_data(split_sequences=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothing = 10e-2\n",
    "V = len(word2idx) + 2\n",
    "M = max(max(y) for y in Ytrain) + 1 # number of hidden states\n",
    "A = np.ones((M, M)) * smoothing # P (tag | tag+1)\n",
    "pi = np.zeros(M)                 # P (tag)\n",
    "for y in Ytrain:\n",
    "    pi[y[0]] += 1\n",
    "    for i in range(len(y) - 1):\n",
    "        A[y[i], y[i+1]] += 1\n",
    "A /= A.sum(axis=1, keepdims=True)\n",
    "pi /= pi.sum()\n",
    "\n",
    "B = np.ones((M, V)) * smoothing # P (word | tag)\n",
    "for x, y in zip(Xtrain, Ytrain):\n",
    "    for xi, yi in zip(x, y):\n",
    "        B[yi, xi] += 1\n",
    "B /= B.sum(axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm = HMM(M)\n",
    "hmm.pi = pi\n",
    "hmm.A = A\n",
    "hmm.B = B\n",
    "\n",
    "Ptrain = []\n",
    "for x in Xtrain:\n",
    "    p = hmm.get_state_sequence(x)\n",
    "    Ptrain.append(p)\n",
    "\n",
    "Ptest = []\n",
    "for x in Xtest:\n",
    "    p = hmm.get_state_sequence(x)\n",
    "    Ptest.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy:  0.9634104294681358\n",
      "test accuracy:  0.9179981847732022\n",
      "train f1 score:  0.9032321066180082\n",
      "test f1 score:  0.8398427947445825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(\"train accuracy: \", accuracy(Ytrain, Ptrain))\n",
    "print(\"test accuracy: \", accuracy(Ytest, Ptest))\n",
    "print(\"train f1 score: \", total_f1_score(Ytrain, Ptrain))\n",
    "print(\"test f1 score: \", total_f1_score(Ytest, Ptest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.9737539378539345\n",
      "test accuracy: 0.9287840091183486\n",
      "train f1: 0.9235279546052866\n",
      "test f1: 0.862609207175332\n"
     ]
    }
   ],
   "source": [
    "%run -i '../vendor/machine_learning_examples/nlp_class2/pos_hmm.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
