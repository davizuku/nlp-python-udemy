{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unifying Word2Vec and Glove\n",
    "\n",
    "Neural word embedding as implicit matrix factorization: http://papers.nips.cc/paper/5477-neural-word-embedding-as-implicit-matrix-factorization.pdf\n",
    "\n",
    "- word2vec: embedding from a neural netword\n",
    "- glove: matrix factorization\n",
    "\n",
    "Overview of glove model: \n",
    "\n",
    "$$ A_{ij} = log(X_{ij}) \\approx w_i^T u_j $$\n",
    "\n",
    "\n",
    "Overview of word2vec cost function: \n",
    "\n",
    "$$ \n",
    "J = \\sum_{w \\in W} \\sum_{c \\in W} count(w, c) \\left \\{ \n",
    "    log \\sigma( \\vec{w}^T \\vec{c} + kE_{n \\sim p(n)} \\left [ \n",
    "        log \\sigma(- \\vec{w}^T \\vec{n})\n",
    "    \\right ]\n",
    "\\right \\}\n",
    "$$\n",
    "- W = set of all words in the vocabulary\n",
    "- w = input word, $\\vec{w}$ = input word vector\n",
    "- c = context word, $\\vec{c}$ = context word vector\n",
    "- n = negative sample, $\\vec{n}$ = negative sample word vector\n",
    "- p(n) = unigram distribution\n",
    "- k = number of negative samples drawn\n",
    "\n",
    "Point of Mutual Information (PMI)\n",
    "\n",
    "Given two discrete random variables $x$ and $y$: \n",
    "\n",
    "$$ PMI(x, y) = log \\frac{P(x, y)}{P(x) P(y)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code\n",
    "\n",
    "- Available in: `../vendor/machine_learning_examples/nlp_class2/pmi.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
